{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi-xnhULN0x6"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d asaniczka/tmdb-movies-dataset-2023-930k-movies\n",
        "!unzip tmdb-movies-dataset-2023-930k-movies.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1zE3_Y6N3Tl"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community\n",
        "!pip install token-count\n",
        "%pip install langchain langchain-community\n",
        "%pip install langchain-openai\n",
        "%pip install pymysql\n",
        "%pip install tidb-vector\n",
        "%pip install --upgrade --quiet  langchain-google-genai pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZD95VGaN8b1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from token_count import TokenCount\n",
        "\n",
        "df = pd.read_csv('TMDB_movie_dataset_v11.csv')\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSX84xoZODVU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from langchain_community.embeddings import JinaEmbeddings\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from PIL import Image\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import TiDBVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "tidb_connection_string = \"YOUR_TIDB_CONNECTION_STRING\"\n",
        "\n",
        "\n",
        "jina_embedding=JinaEmbeddings(jina_api_key='YOUR_JINA_API_KEY', model_name=\"jina-embeddings-v2-base-en\")\n",
        "\n",
        "TABLE_NAME = \"YOUR_TABLE_NAME\"\n",
        "\n",
        "db = TiDBVectorStore.from_texts(\n",
        "    texts=[\n",
        "        \"\"\n",
        "    ],\n",
        "    embedding=jina_embedding,\n",
        "    table_name=TABLE_NAME,\n",
        "    connection_string=tidb_connection_string,\n",
        "    distance_strategy=\"cosine\",  # default, another option is \"l2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuDefmdKOYeo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('TMDB_movie_dataset_v11.csv')\n",
        "df.head(10)\n",
        "\n",
        "text_datasets_with_metadata = []\n",
        "# metadatas\n",
        "for index, row in df.iterrows():\n",
        "  tagline = row['tagline']\n",
        "  if tagline == None or tagline!=tagline:\n",
        "    tagline = \"\"\n",
        "  metadata = {\n",
        "      \"id\": row['id'],\n",
        "      \"title\": row['title'],\n",
        "      \"tagline\": tagline,\n",
        "      \"genres\": row['genres'],\n",
        "      \"release_date\": row['release_date'],\n",
        "      \"budget\": row['budget'],\n",
        "      \"revenue\": row['revenue'],\n",
        "      \"runtime\": row['runtime'],\n",
        "      \"popularity\": row['popularity'],\n",
        "      \"vote_average\": row['vote_average'],\n",
        "      \"vote_count\": row['vote_count']\n",
        "  }\n",
        "  text_datasets_with_metadata.append({\n",
        "      \"text\": row['overview'],\n",
        "      \"metadata\": metadata\n",
        "  })\n",
        "\n",
        "print(text_datasets_with_metadata[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaBOXJxfOiWZ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Function to process each text_data item\n",
        "def process_text_data(i, text_data, added_indices, db):\n",
        "    if i in added_indices:\n",
        "        return None\n",
        "\n",
        "    if not text_data[\"metadata\"]:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        db.add_texts(\n",
        "            texts=[text_data[\"text\"]],\n",
        "            metadatas=[text_data[\"metadata\"]]\n",
        "        )\n",
        "        # If successful, return the index to add to the list\n",
        "        return i\n",
        "    except Exception as e:\n",
        "        print(\"ERROR: \" + text_data[\"metadata\"][\"id\"])\n",
        "        return None\n",
        "\n",
        "# Load existing added indices from file, if it exists\n",
        "try:\n",
        "    with open('added_indices.json', 'r') as f:\n",
        "        added_indices = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    added_indices = []\n",
        "\n",
        "# Create a ThreadPoolExecutor for multithreading\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    futures = []\n",
        "\n",
        "    for i, text_data in enumerate(text_datasets_with_metadata)\n",
        "    futures.append(executor.submit(process_text_data, i, text_data, added_indices, db))\n",
        "\n",
        "    # Process the results as they complete\n",
        "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "      result = future.result()\n",
        "      if result is not None:\n",
        "        added_indices.append(result)\n",
        "        with open('added_indices.json', 'w') as f:\n",
        "          json.dump(added_indices, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
